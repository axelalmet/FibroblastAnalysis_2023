{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49f5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where we will load the h5ad file\n",
    "results_directory = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ce6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the relevant packages.\n",
    "# First load the packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanorama as scrama\n",
    "from scipy import sparse\n",
    "\n",
    "sc.settings.verbosity = 3 # Possible values: (0) errors, (1) warnings, (2) info, (3) hints\n",
    "sc.settings.set_figure_params(dpi = 100, facecolor='white', fontsize=18, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba847a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save so we don't lose all the good work from Scanorama.\n",
    "init_results_name = 'integratedskindata.h5ad'\n",
    "wound_full_merged = sc.read_h5ad(results_directory + init_results_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339abfa8",
   "metadata": {},
   "source": [
    "Subset the integrated data for the various major cell types for further subclustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Epidermal')]\n",
    "fibroblast_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Fibroblast')]\n",
    "immune_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Immune')]\n",
    "endothelial_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Endothelial')]\n",
    "pericyte_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Pericyte')]\n",
    "schwann_merged = wound_full_merged[wound_full_merged.obs['leiden'].str.startswith('Schwann')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784aa06",
   "metadata": {},
   "source": [
    "# Subclustering fibroblasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(fibroblast_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(fibroblast_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = fibroblast_merged.var['dispersions_norm'][fibroblast_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_fibroblast = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_fibroblast) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = fibroblast_merged.var['dispersions_norm'][fibroblast_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_fibroblast = hvg_fibroblast.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_fibroblast = hvg_fibroblast.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52615aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fibroblast_merged_hvg = fibroblast_merged.copy()\n",
    "fibroblast_merged_hvg = fibroblast_merged_hvg[:, hvg_fibroblast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab87c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "fibroblast_split = []\n",
    "\n",
    "for sample in fibroblast_merged_hvg.obs['sample'].unique():\n",
    "    fibroblast_split.append(fibroblast_merged_hvg[fibroblast_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74084a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data.\n",
    "scrama.integrate_scanpy(fibroblast_split, ds_names = list(fibroblast_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fibroblast = [adata.obsm['X_scanorama'] for adata in fibroblast_split]\n",
    "embeddings_fibroblast_joined = np.concatenate(embeddings_fibroblast, axis=0)\n",
    "fibroblast_merged.obsm['X_SC_FIB'] = embeddings_fibroblast_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(fibroblast_merged, use_rep = 'X_SC_FIB', n_neighbors=30)\n",
    "sc.tl.umap(fibroblast_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66cd66",
   "metadata": {},
   "source": [
    "We find that we need to recluster the fibroblasts twice, to remove a subset of erythrocytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40810b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(fibroblast_merged, resolution = 0.5, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba693c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fibroblast_merged = fibroblast_merged[fibroblast_merged.obs['leiden_sub'] != '11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(fibroblast_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(fibroblast_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = fibroblast_merged.var['dispersions_norm'][fibroblast_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_fibroblast = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_fibroblast) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = fibroblast_merged.var['dispersions_norm'][fibroblast_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_fibroblast = hvg_fibroblast.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_fibroblast = hvg_fibroblast.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fibroblast_merged_hvg = fibroblast_merged.copy()\n",
    "fibroblast_merged_hvg = fibroblast_merged_hvg[:, hvg_fibroblast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80705d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "fibroblast_split = []\n",
    "\n",
    "for sample in fibroblast_merged_hvg.obs['sample'].unique():\n",
    "    fibroblast_split.append(fibroblast_merged_hvg[fibroblast_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1433eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data.\n",
    "scrama.integrate_scanpy(fibroblast_split, ds_names = list(fibroblast_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fibroblast = [adata.obsm['X_scanorama'] for adata in fibroblast_split]\n",
    "embeddings_fibroblast_joined = np.concatenate(embeddings_fibroblast, axis=0)\n",
    "fibroblast_merged.obsm['X_SC_FIB'] = embeddings_fibroblast_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68206eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(fibroblast_merged, use_rep = 'X_SC_FIB', n_neighbors=30)\n",
    "sc.tl.umap(fibroblast_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(fibroblast_merged, resolution = 0.7, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(fibroblast_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837076ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "fibroblast_cluster_names = ['FIB-I', 'FIB-II', 'FIB-III', 'FIB-IV',\\\n",
    "                            'FIB-V', 'FIB-VI', 'FIB-VII', 'FIB-VIII',\n",
    "                            'FIB-IX', 'FIB-X', 'FIB-XI']\n",
    "fibroblast_merged.rename_categories('leiden_sub', fibroblast_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce95d1",
   "metadata": {},
   "source": [
    "Save the fibroblasts as a separate file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a626921",
   "metadata": {},
   "outputs": [],
   "source": [
    "fibroblasts_file_name = 'integratedfibroblastsdata.h5ad'\n",
    "fibroblast_merged.write(results_directory + fibroblasts_file_name, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2564d3",
   "metadata": {},
   "source": [
    "# Subclustering immune cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(immune_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(immune_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = immune_merged.var['dispersions_norm'][immune_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_immune = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_immune) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = immune_merged.var['dispersions_norm'][immune_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_immune = hvg_immune.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_immune = hvg_immune.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_merged_hvg = immune_merged.copy()\n",
    "immune_merged_hvg = immune_merged_hvg[:, hvg_immune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "immune_split = []\n",
    "\n",
    "for sample in immune_merged_hvg.obs['sample'].unique():\n",
    "    immune_split.append(immune_merged_hvg[immune_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfa0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(immune_split, ds_names = list(immune_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_immune = [adata.obsm['X_scanorama'] for adata in immune_split]\n",
    "embeddings_immune_joined = np.concatenate(embeddings_immune, axis=0)\n",
    "immune_merged.obsm['X_SC_IMM'] = embeddings_immune_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(immune_merged, use_rep = 'X_SC_IMM', n_neighbors=30)\n",
    "sc.tl.umap(immune_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(immune_merged, resolution = 0.4, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b76b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(immune_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b07a9e",
   "metadata": {},
   "source": [
    "Cluster 13 is Erythrocytes, so let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_merged = immune_merged[immune_merged.obs['leiden_sub'] != '13']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ad664",
   "metadata": {},
   "source": [
    "Rerun the integration again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9de1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(immune_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(immune_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = immune_merged.var['dispersions_norm'][immune_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_immune = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_immune) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = immune_merged.var['dispersions_norm'][immune_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_immune = hvg_immune.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_immune = hvg_immune.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_merged_hvg = immune_merged.copy()\n",
    "immune_merged_hvg = immune_merged_hvg[:, hvg_immune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed182f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "immune_split = []\n",
    "\n",
    "for sample in immune_merged_hvg.obs['sample'].unique():\n",
    "    immune_split.append(immune_merged_hvg[immune_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9419277",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(immune_split, ds_names = list(immune_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_immune = [adata.obsm['X_scanorama'] for adata in immune_split]\n",
    "embeddings_immune_joined = np.concatenate(embeddings_immune, axis=0)\n",
    "immune_merged.obsm['X_SC_IMM'] = embeddings_immune_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(immune_merged, use_rep = 'X_SC_IMM', n_neighbors=30)\n",
    "sc.tl.umap(immune_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(immune_merged, resolution = 0.3, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(immune_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15439d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "immune_cluster_names = ['MAC-1', 'TCELL', 'DC-1', 'MAC-2',\\\n",
    "                        'MAC-3', 'DC-2', 'DC-3', 'NEU',\\\n",
    "                        'MAC-4', 'MAC-5', 'NK', 'BASO', 'pDC',\\\n",
    "                        'MAST']\n",
    "immune_merged.rename_categories('leiden_sub', immune_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f83e8",
   "metadata": {},
   "source": [
    "## Subcluster T cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcells_merged = immune_merged[immune_merged.obs['leiden_sub'].str.startswith('TCELL')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2499ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(tcells_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(tcells_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = tcells_merged.var['dispersions_norm'][tcells_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_tcells = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_tcells) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = tcells_merged.var['dispersions_norm'][tcells_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_tcells = hvg_tcells.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_tcells = hvg_tcells.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f77222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcells_merged_hvg = tcells_merged.copy()\n",
    "tcells_merged_hvg = tcells_merged_hvg[:, hvg_tcells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51160037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "tcells_split = []\n",
    "\n",
    "for sample in tcells_merged_hvg.obs['sample'].unique():\n",
    "    tcells_split.append(tcells_merged_hvg[tcells_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65838994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(tcells_split, ds_names = list(tcells_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tcells = [adata.obsm['X_scanorama'] for adata in tcells_split]\n",
    "embeddings_tcells_joined = np.concatenate(embeddings_tcells, axis=0)\n",
    "tcells_merged.obsm['X_SC_TC'] = embeddings_tcells_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2790db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(tcells_merged, use_rep = 'X_SC_TC', n_neighbors=30)\n",
    "sc.tl.umap(tcells_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf71118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(tcells_merged, resolution = 0.3, key_added = 'leiden_tcell')\n",
    "sc.pl.umap(tcells_merged, color='leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "tcell_cluster_names = ['T-reg', 'NKT', 'ILC', 'CYC-T', 'ACT-T']\n",
    "tcells_merged.rename_categories('leiden_sub', tcell_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e687f",
   "metadata": {},
   "source": [
    "# Subclustering epidermal cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a18a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the Seurat flavour this time because some conditions are missing epidermal cells\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(epidermis_merged, flavor='seurat', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(epidermis_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = epidermis_merged.var['dispersions_norm'][epidermis_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_epidermis = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_epidermis) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = epidermis_merged.var['dispersions_norm'][epidermis_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_epidermis = hvg_epidermis.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_epidermis = hvg_epidermis.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged_hvg = epidermis_merged.copy()\n",
    "epidermis_merged_hvg = epidermis_merged_hvg[:, hvg_epidermis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "epidermis_split = []\n",
    "\n",
    "for sample in epidermis_merged_hvg.obs['sample'].unique():\n",
    "    epidermis_split.append(epidermis_merged_hvg[epidermis_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fcd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scanorama to integrate the epidermal data\n",
    "scrama.integrate_scanpy(epidermis_split, ds_names = list(epidermis_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_epidermis = [adata.obsm['X_scanorama'] for adata in epidermis_split]\n",
    "embeddings_epidermis_joined = np.concatenate(embeddings_epidermis, axis=0)\n",
    "epidermis_merged.obsm['X_SC_EPI'] = embeddings_epidermis_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b116d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(epidermis_merged, use_rep = 'X_SC_EPI', n_neighbors=30)\n",
    "sc.tl.umap(epidermis_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdc5a6",
   "metadata": {},
   "source": [
    "We found that we had to do two rounds of clustering. The first round, we need to filter out erythrocytes, marked by Hba-a1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f419992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(epidermis_merged, resolution = 0.3, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadea22c",
   "metadata": {},
   "source": [
    "We will do this again, as subcluster 9 is definitely red blood cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged = epidermis_merged[epidermis_merged.obs['leiden_sub'] != '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89119fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(epidermis_merged, flavor='seurat', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(epidermis_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = epidermis_merged.var['dispersions_norm'][epidermis_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_epidermis = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_epidermis) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = epidermis_merged.var['dispersions_norm'][epidermis_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_epidermis = hvg_epidermis.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_epidermis = hvg_epidermis.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged_hvg = epidermis_merged.copy()\n",
    "epidermis_merged_hvg = epidermis_merged_hvg[:, hvg_epidermis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ef016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "epidermis_split = []\n",
    "\n",
    "for sample in epidermis_merged_hvg.obs['sample'].unique():\n",
    "    epidermis_split.append(epidermis_merged_hvg[epidermis_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrama.integrate_scanpy(epidermis_split, ds_names = list(epidermis_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_epidermis = [adata.obsm['X_scanorama'] for adata in epidermis_split]\n",
    "embeddings_epidermis_joined = np.concatenate(embeddings_epidermis, axis=0)\n",
    "epidermis_merged.obsm['X_SC_EPI'] = embeddings_epidermis_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(epidermis_merged, use_rep = 'X_SC_EPI', n_neighbors=30)\n",
    "sc.tl.umap(epidermis_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27191ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(epidermis_merged, resolution=0.6, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a583d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(epidermis_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2daee",
   "metadata": {},
   "source": [
    "We identified one subcluster as cycling epidermal cells, based on cell cycle gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_cycle_genes = pd.read_csv(results_directory + 'regev_lab_cell_cycle_genes.txt', header=None)[0].tolist()\n",
    "cell_cycle_genes = list(map(lambda x: x[0] + x[1:].lower(), cell_cycle_genes))\n",
    "s_genes = cell_cycle_genes[:43]\n",
    "g2m_genes = cell_cycle_genes[43:]\n",
    "cell_cycle_genes = [x for x in cell_cycle_genes if x in epidermis_merged.var_names]\n",
    "\n",
    "# Score for cell cycle genes\n",
    "sc.tl.score_genes_cell_cycle(epidermis_merged, s_genes=s_genes, g2m_genes=g2m_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e397ff",
   "metadata": {},
   "source": [
    "Rename the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c80b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_cluster_names = ['CYC-1', 'WO-1', 'BAS-1',\\\n",
    "                           'SPN-1', 'WO-2', 'BAS-2',\\\n",
    "                           'BAS-3', 'HF-1', 'WO-3',\\\n",
    "                           'BAS-4', 'BAS-5', 'HF-2',\\\n",
    "                           'WO-4', 'CYC-2']\n",
    "epidermis_merged.rename_categories('leiden_sub', epidermis_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3c5c6",
   "metadata": {},
   "source": [
    "# Subclustering pericytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4149a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(pericyte_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(pericyte_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = pericyte_merged.var['dispersions_norm'][pericyte_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_pericyte = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_pericyte) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = pericyte_merged.var['dispersions_norm'][pericyte_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_pericyte = hvg_pericyte.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_pericyte = hvg_pericyte.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pericyte_merged_hvg = pericyte_merged.copy()\n",
    "pericyte_merged_hvg = pericyte_merged_hvg[:, hvg_pericyte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "pericyte_split = []\n",
    "\n",
    "for sample in pericyte_merged_hvg.obs['sample'].unique():\n",
    "    pericyte_split.append(pericyte_merged_hvg[pericyte_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(pericyte_split, ds_names = list(pericyte_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d12dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pericyte = [adata.obsm['X_scanorama'] for adata in pericyte_split]\n",
    "embeddings_pericyte_joined = np.concatenate(embeddings_pericyte, axis=0)\n",
    "pericyte_merged.obsm['X_SC_PERI'] = embeddings_pericyte_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(pericyte_merged, use_rep = 'X_SC_PERI', n_neighbors=30)\n",
    "sc.tl.umap(pericyte_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(pericyte_merged, resolution = 0.4, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(pericyte_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a303dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "pericyte_cluster_names = ['PERI-1', 'PERI-2', 'PERI-3', 'PERI-4', 'PERI-5']\n",
    "pericyte_merged.rename_categories('leiden_sub', pericyte_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb9433",
   "metadata": {},
   "source": [
    "# Subclustering endothelial cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(endothelial_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(endothelial_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = endothelial_merged.var['dispersions_norm'][endothelial_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_endothelial = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_endothelial) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = endothelial_merged.var['dispersions_norm'][endothelial_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_endothelial = hvg_endothelial.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_endothelial = hvg_endothelial.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "endothelial_merged_hvg = endothelial_merged.copy()\n",
    "endothelial_merged_hvg = endothelial_merged_hvg[:, hvg_endothelial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "endothelial_split = []\n",
    "\n",
    "for sample in endothelial_merged_hvg.obs['sample'].unique():\n",
    "    endothelial_split.append(endothelial_merged_hvg[endothelial_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d14602",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(endothelial_split, ds_names = list(endothelial_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_endothelial = [adata.obsm['X_scanorama'] for adata in endothelial_split]\n",
    "embeddings_endothelial_joined = np.concatenate(embeddings_endothelial, axis=0)\n",
    "endothelial_merged.obsm['X_SC_ENDO'] = embeddings_endothelial_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(endothelial_merged, use_rep = 'X_SC_ENDO', n_neighbors=30)\n",
    "sc.tl.umap(endothelial_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(endothelial_merged, resolution = 0.3, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(endothelial_merged, 'leiden_sub', key_added = 'leiden_sub', method='wilcoxon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c119b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "endothelial_cluster_names = ['ENDO-1', 'ENDO-2', 'ENDO-3', 'ENDO-4']\n",
    "endothelial_merged.rename_categories('leiden_sub', endothelial_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d514f37",
   "metadata": {},
   "source": [
    "# Subclustering Schwann cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highly-variable genes. We use the CellRanger routine provided in Scanpy.\n",
    "target_genes = 2000\n",
    "sc.pp.highly_variable_genes(schwann_merged, flavor='cell_ranger', n_top_genes=target_genes, batch_key='sample')\n",
    "\n",
    "# As we don't have enough target genes, we need to consider HVGs in all but one batches.\n",
    "n_batches = len(schwann_merged.obs['sample'].cat.categories)\n",
    "# These are the genes that are variable across all batches\n",
    "nbatch1_dispersions = schwann_merged.var['dispersions_norm'][schwann_merged.var.highly_variable_nbatches > n_batches - 1]\n",
    "nbatch1_dispersions.sort_values(ascending=False, inplace=True)\n",
    "print(len(nbatch1_dispersions))\n",
    "\n",
    "# Fill up the genes now, using this method from the Theis lab\n",
    "enough = False\n",
    "hvg_schwann = nbatch1_dispersions.index[:]\n",
    "not_n_batches = 1\n",
    "\n",
    "# We'll go down one by one, until we're selecting HVGs from just a single gbatch\n",
    "while not enough:\n",
    "    \n",
    "    target_genes_diff = target_genes - len(hvg_schwann) # Get the number of genes we still need to fill up\n",
    "    \n",
    "    tmp_dispersions = schwann_merged.var['dispersions_norm'][schwann_merged.var.highly_variable_nbatches == (n_batches - not_n_batches)]\n",
    "    \n",
    "    # If we haven't hit the target gene numbers, add this to the list and we repeat this iteration\n",
    "    if len(tmp_dispersions) < target_genes_diff:\n",
    "        \n",
    "        hvg_schwann = hvg_schwann.append(tmp_dispersions.index)\n",
    "        not_n_batches += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "        hvg_schwann = hvg_schwann.append(tmp_dispersions.index[:target_genes_diff])\n",
    "        enough = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "schwann_merged_hvg = schwann_merged.copy()\n",
    "schwann_merged_hvg = schwann_merged_hvg[:, hvg_schwann]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7de001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into batches (marked by 'sample')\n",
    "schwann_split = []\n",
    "\n",
    "for sample in schwann_merged_hvg.obs['sample'].unique():\n",
    "    schwann_split.append(schwann_merged_hvg[schwann_merged_hvg.obs['sample']==sample].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run Scanorama on the split data. (I find that we don't really need the batch-corrected data for these datasets)\n",
    "scrama.integrate_scanpy(schwann_split, ds_names = list(schwann_merged_hvg.obs['sample'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_schwann = [adata.obsm['X_scanorama'] for adata in schwann_split]\n",
    "embeddings_schwann_joined = np.concatenate(embeddings_schwann, axis=0)\n",
    "schwann_merged.obsm['X_SC_SCH'] = embeddings_schwann_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3420bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA just to see the variation across samples\n",
    "sc.pp.neighbors(schwann_merged, use_rep = 'X_SC_SCH', n_neighbors=30)\n",
    "sc.tl.umap(schwann_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data now\n",
    "sc.tl.leiden(schwann_merged, resolution = 0.4, key_added = 'leiden_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981089d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the clusters\n",
    "schwann_cluster_names = ['SCH-1', 'SCH-2', 'SCH-3', 'SCH-4', 'SCH-5']\n",
    "schwann_merged.rename_categories('leiden_sub', schwann_cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa919f5",
   "metadata": {},
   "source": [
    "# Merge subcluster labels to the original scanpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf33cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged_copy = epidermis_merged.copy()\n",
    "fibroblast_merged_copy = fibroblasts_merged.copy()\n",
    "immune_merged_copy = immune_merged.copy()\n",
    "tcells_merged_copy = tcells_merged.copy()\n",
    "pericyte_merged_copy = pericyte_merged.copy()\n",
    "endothelial_merged_copy = endothelial_merged.copy()\n",
    "schwann_merged_copy = schwann_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epidermis_merged_copy.obs = pd.DataFrame(epidermis_merged_copy.obs['leiden_sub'])\n",
    "fibroblast_merged_copy.obs = pd.DataFrame(fibroblast_merged_copy.obs['leiden_sub'])\n",
    "immune_merged_copy.obs = pd.DataFrame(immune_merged_copy.obs['leiden_sub'])\n",
    "tcells_merged_copy.obs = pd.DataFrame(tcells_merged_copy.obs['leiden_sub'])\n",
    "pericyte_merged_copy.obs = pd.DataFrame(pericyte_merged_copy.obs['leiden_sub'])\n",
    "endothelial_merged_copy.obs = pd.DataFrame(endothelial_merged_copy.obs['leiden_sub'])\n",
    "schwann_merged_copy.obs = pd.DataFrame(schwann_merged_copy.obs['leiden_sub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68bf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fibroblast  labels initially to create the 'sub_leiden' column\n",
    "wound_full_merged.obs = wound_full_merged.obs.merge(fibroblast_merged_copy.obs, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Update the sub leiden column with the subcluster labels for other cells\n",
    "wound_full_merged.obs.update(epidermis_merged_copy.obs)\n",
    "wound_full_merged.obs.update(fibroblast_merged_copy.obs)\n",
    "wound_full_merged.obs.update(immune_merged_copy.obs)\n",
    "wound_full_merged.obs.update(tcells_merged_copy.obs)\n",
    "wound_full_merged.obs.update(pericyte_merged_copy.obs)\n",
    "wound_full_merged.obs.update(endothelial_merged_copy.obs)\n",
    "wound_full_merged.obs.update(schwann_merged_copy.obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72684443",
   "metadata": {},
   "source": [
    "For all other cells that were not subclustered, we use the original 'leiden' label. Except for those that we have identified as erythrocytes, we mark as such (red blood cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find the cells that haven't been subclustered\n",
    "non_subclustered_cells = []\n",
    "for cell in wound_full_merged.obs.index:\n",
    "    has_cell_been_subclustered = False\n",
    "    # Essentially if this cell isn't in any of the above subclustered anndata objects, we need to account for it\n",
    "    if (cell in epidermis_merged.obs.index)\\\n",
    "    |(cell in fibroblasts_merged.obs.index)\\\n",
    "    |(cell in immune_merged.obs.index)\\\n",
    "    |(cell in pericyte_merged.obs.index)\\\n",
    "    |(cell in endothelial_merged.obs.index)\\\n",
    "    |(cell in tcells_merged.obs.index)\\\n",
    "    |(cell in schwann_merged.obs.index):\n",
    "        has_cell_been_subclustered = True\n",
    "    \n",
    "    if not has_cell_been_subclustered:\n",
    "        non_subclustered_cells.append(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee298d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now determine the leiden_sub label\n",
    "for cell in non_subclustered_cells:\n",
    "    leiden_cluster = wound_merged_nonsubclustered.obs['leiden'][cell]\n",
    "    leiden_sub_cluster = leiden_cluster\n",
    "    # If the cell was originally in the keratinocytes, or fibroblasts, or immune cells\n",
    "    # but hasn't been subclustered, it was because it was an erythrocyte. We'll mark it as such\n",
    "    if (leiden_cluster.startswith('Epidermal'))\\\n",
    "        |(leiden_cluster.startswith('Fib'))\\\n",
    "        |(leiden_cluster.startswith('Immune')):\n",
    "        leiden_sub_cluster = 'Erythrocyte'\n",
    "        \n",
    "    wound_merged_nonsubclustered.obs['leiden_sub'][cell] = leiden_sub_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the other clusters now\n",
    "wound_merged_nonsubclustered_copy = wound_merged_nonsubclustered.copy()\n",
    "wound_merged_nonsubclustered_copy.obs = pd.DataFrame(wound_merged_nonsubclustered_copy.obs['leiden_sub'])\n",
    "wound_full_merged.obs.update(wound_merged_nonsubclustered_copy.obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc48ec",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wound_full_merged.write(results_directory + init_results_name, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
